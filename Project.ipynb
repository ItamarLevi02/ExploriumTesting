{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "import requests\n",
    "import os\n",
    "from typing import Optional\n",
    "import PyPDF2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "explorium_api_key = os.getenv(\"EXPLORIUM_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyContextReader(BaseTool):\n",
    "    name: str = \"company_context_reader\"\n",
    "    description: str = \"Reads company information files to understand DataGuardian AI's offerings and value proposition\"\n",
    "    return_direct: bool = False\n",
    "    context_dir: str = \"company_context\"\n",
    "    \n",
    "    def __init__(self, context_dir: Optional[str] = None):\n",
    "        super().__init__()\n",
    "        if context_dir:\n",
    "            self.context_dir = context_dir\n",
    "        os.makedirs(self.context_dir, exist_ok=True)\n",
    "    \n",
    "    def _run(self, query: str = \"\") -> str:\n",
    "        context = []\n",
    "        for filename in os.listdir(self.context_dir):\n",
    "            filepath = os.path.join(self.context_dir, filename)\n",
    "            try:\n",
    "                if filename.endswith('.pdf'):\n",
    "                    with open(filepath, 'rb') as file:\n",
    "                        pdf_reader = PyPDF2.PdfReader(file)\n",
    "                        text = \"\"\n",
    "                        for page in pdf_reader.pages:\n",
    "                            text += page.extract_text() + \"\\n\"\n",
    "                        context.append(f\"Content from {filename}:\\n{text}\")\n",
    "                elif filename.endswith('.txt'):\n",
    "                    with open(filepath, 'r') as file:\n",
    "                        text = file.read()\n",
    "                        context.append(f\"Content from {filename}:\\n{text}\")\n",
    "            except Exception as e:\n",
    "                context.append(f\"Error reading {filename}: {str(e)}\")\n",
    "        \n",
    "        if not context:\n",
    "            return \"No context files found. Please provide company/product information files.\"\n",
    "        \n",
    "        return \"\\n\\n---\\n\\n\".join(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyResearcher(BaseTool):\n",
    "    name: str = \"company_researcher\"\n",
    "    description: str = \"Get detailed firmographic information about a company using its business ID\"\n",
    "    return_direct: bool = False\n",
    "    \n",
    "    def _run(self, business_id: str) -> str:\n",
    "        api_key = explorium_api_key\n",
    "        url = \"https://api.explorium.ai/v1/businesses/firmographics/enrich\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"api_key\": api_key\n",
    "        }\n",
    "        payload = {\"business_id\": business_id}\n",
    "        \n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json().get(\"data\", {})\n",
    "            firmographics = {\n",
    "                \"company_name\": data.get(\"name\"),\n",
    "                \"description\": data.get(\"business_description\"),\n",
    "                \"location\": f\"{data.get('country_name', 'N/A')}, {data.get('region_name', 'N/A')}\",\n",
    "                \"industry\": data.get(\"naics_description\"),\n",
    "                \"employee_range\": data.get(\"number_of_employees_range\"),\n",
    "                \"revenue_range\": data.get(\"yearly_revenue_range\"),\n",
    "                \"linkedin\": data.get(\"linkedin_profile\")\n",
    "            }\n",
    "            return str(firmographics)\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "    async def _arun(self, business_id: str) -> str:\n",
    "        raise NotImplementedError(\"Async version not implemented\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedInPostAnalyzer(BaseTool):\n",
    "    name: str = \"linkedin_post_analyzer\"\n",
    "    description: str = \"Analyze recent LinkedIn posts from a company using its business ID to understand their current focus and initiatives\"\n",
    "    return_direct: bool = False\n",
    "    \n",
    "    def _run(self, business_id: str) -> str:\n",
    "        api_key = explorium_api_key\n",
    "        url = \"https://api.explorium.ai/v1/businesses/linkedin_posts/enrich\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"api_key\": api_key\n",
    "        }\n",
    "        payload = {\"business_id\": business_id}\n",
    "        \n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            posts = response.json().get(\"data\", [])\n",
    "            \n",
    "            # Get the 5 most recent posts (sorted by days_since_posted)\n",
    "            sorted_posts = sorted(posts, key=lambda x: x.get('days_since_posted', float('inf')))\n",
    "            recent_posts = sorted_posts[:5]\n",
    "            \n",
    "            # Format the posts\n",
    "            formatted_posts = []\n",
    "            for post in recent_posts:\n",
    "                formatted_post = {\n",
    "                    \"date\": post.get(\"created_at\"),\n",
    "                    \"content\": post.get(\"post_text\"),\n",
    "                    \"likes\": post.get(\"number_of_likes\"),\n",
    "                    \"comments\": post.get(\"number_of_comments\"),\n",
    "                    \"url\": post.get(\"post_url\"),\n",
    "                    \"days_since_posted\": post.get(\"days_since_posted\")\n",
    "                }\n",
    "                formatted_posts.append(formatted_post)\n",
    "            \n",
    "            return str({\"recent_posts\": formatted_posts})\n",
    "        return f\"Error: {response.status_code}, {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Challenges Tool\n",
    "class BusinessChallengesAnalyzer(BaseTool):\n",
    "    name: str = \"business_challenges_analyzer\"\n",
    "    description: str = \"Analyze business challenges and risks for a company using its business ID\"\n",
    "    return_direct: bool = False\n",
    "    \n",
    "    def _run(self, business_id: str) -> str:\n",
    "        api_key = explorium_api_key\n",
    "        url = \"https://api.explorium.ai/v1/businesses/pc_business_challenges_10k/enrich\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"api_key\": api_key\n",
    "        }\n",
    "        payload = {\"business_id\": business_id}\n",
    "        \n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json().get(\"data\", {})\n",
    "            challenges = {\n",
    "                \"technological_disruption\": \", \".join(data.get(\"technological_disruption\", [])),\n",
    "                \"security_breach\": \", \".join(data.get(\"company_data_security_breach\", [])),\n",
    "                \"market_saturation\": \", \".join(data.get(\"company_market_saturation\", [])),\n",
    "                \"competition\": \", \".join(data.get(\"company_competition\", [])),\n",
    "                \"customer_adoption\": \", \".join(data.get(\"company_customer_adoption\", []))\n",
    "            }\n",
    "            return str(challenges)\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "    async def _arun(self, business_id: str) -> str:\n",
    "        raise NotImplementedError(\"Async version not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_pitch(openai_api_key: str, business_id: str, context_dir: str = \"company_context\") -> str:\n",
    "    \"\"\"\n",
    "    Generate and save a personalized sales pitch using DataGuardian AI's context files and target company research.\n",
    "    \n",
    "    Args:\n",
    "        openai_api_key (str): OpenAI API key\n",
    "        business_id (str): Target company's business ID\n",
    "        context_dir (str): Directory containing context files about DataGuardian AI\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the saved sales pitch file\n",
    "    \"\"\"\n",
    "    # Initialize the language model\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4\",\n",
    "        openai_api_key=openai_api_key\n",
    "    )\n",
    "    \n",
    "    # Initialize all tools\n",
    "    tools = [\n",
    "        CompanyContextReader(context_dir=context_dir),\n",
    "        CompanyResearcher(),\n",
    "        BusinessChallengesAnalyzer(),\n",
    "        LinkedInPostAnalyzer()\n",
    "    ]\n",
    "    \n",
    "    # Create the agent with an updated prompt\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "        max_iterations=5,\n",
    "        early_stopping_method=\"generate\",\n",
    "        agent_kwargs={\n",
    "            \"prefix\": \"\"\"You are an expert sales development representative for DataGuardian AI, tasked with creating highly personalized sales emails. \n",
    "            You specialize in selling data security and governance solutions to enterprises using data cloud platforms.\n",
    "            \n",
    "            Follow these steps in order:\n",
    "            \n",
    "            1. Use the company_context_reader tool to understand DataGuardian AI's offerings, success metrics, and case studies\n",
    "            2. Research the target company using their business ID with the CompanyResearcher tool\n",
    "            3. Analyze their business challenges using the BusinessChallengesAnalyzer tool\n",
    "            4. Review their recent LinkedIn activity using the LinkedInPostAnalyzer tool\n",
    "            5. Create a compelling, personalized sales pitch that:\n",
    "               - Shows deep understanding of their data security and governance needs\n",
    "               - Addresses specific compliance and security challenges they face\n",
    "               - Demonstrates how DataGuardian AI's solution complements their existing data infrastructure\n",
    "               - References relevant case studies and metrics from similar clients\n",
    "               - Emphasizes the seamless integration with their current tech stack\n",
    "            \n",
    "            Format the output as:\n",
    "            # Sales Pitch for [Company Name]\n",
    "            \n",
    "            ## Subject Line\n",
    "            [Compelling subject line focusing on data security/governance value]\n",
    "            \n",
    "            ## Personalized Message\n",
    "            [Warm introduction]\n",
    "            [Show understanding of their business and current data initiatives]\n",
    "            [Address specific security/compliance challenges]\n",
    "            [Present DataGuardian AI's relevant solution]\n",
    "            [Include success metrics from similar case studies]\n",
    "            \n",
    "            ## Value Proposition\n",
    "            [List 3-4 specific benefits for their use case]\n",
    "            [Include relevant metrics from our case studies]\n",
    "            \n",
    "            ## Call to Action\n",
    "            [Specific next steps for a technical demo]\n",
    "            \n",
    "            Generated: [Current Date]\"\"\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Generate the sales pitch\n",
    "    result = agent.run(f\"\"\"Create a personalized sales pitch for {business_id}. First understand DataGuardian AI's offerings \n",
    "    from the context files, then research {business_id} to create a compelling pitch focusing on their specific data \n",
    "    security and governance needs. Emphasize how we complement their existing data cloud infrastructure.\"\"\")\n",
    "    \n",
    "    # Simplify the filename creation - just use the business_id instead of trying to extract company name\n",
    "    company_name = business_id.replace(' ', '_').lower()\n",
    "    \n",
    "    # Create sales_pitches directory if it doesn't exist\n",
    "    os.makedirs('sales_pitches', exist_ok=True)\n",
    "    \n",
    "    # Add current date to the result\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    result += f\"\\n\\nGenerated: {current_date}\"\n",
    "    \n",
    "    # Save the pitch to a markdown file\n",
    "    filename = f\"sales_pitches/{company_name}_sales_pitch.md\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    return f\"Sales pitch has been saved to {filename}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_and_save_pitch(\n",
    "    openai_api_key=openai_api_key,\n",
    "    business_id=\"e921d7dce42fbcb84bb2110d925ad778\",\n",
    "    context_dir=\"company_context\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
